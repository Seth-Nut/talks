import streamlit as st
from openai import OpenAI

# ConfiguraciÃ³n
st.set_page_config(page_title="Explorador de Prompts", layout="centered")
st.title("ğŸ¤– Explorador de Prompts + Chatbot")

# Ingreso de API Key
st.session_state.api_key = st.text_input(
    "ğŸ”‘ Ingresa tu OpenAI API Key (no se guarda):", type="password", placeholder="sk-..."
)

# --- CLIENTE ---
if st.session_state.api_key.startswith("sk-"):
    client = OpenAI(api_key=st.session_state.api_key)

# --- CATEGORÃAS Y TIPOS ---
categorias = {
    "ğŸ§­ Prompt directo o instrucciÃ³n": [
        "Pregunta directa",
        "InstrucciÃ³n",
        "Comando",
    ],
    "ğŸ§  TÃ©cnicas de prompting": [
        "Zero-shot",
        "Few-shot",
        "CoT (Chain-of-Thought)",
        "Chaining",
    ],
    "âš–ï¸ Ã‰tica y privacidad": [
        "Credenciales",
        "Privacidad",
        "Tareas",
    ]
}

explicaciones = {
    "Pregunta directa": "Un prompt que hace una pregunta especÃ­fica esperando una respuesta concreta.",
    "InstrucciÃ³n": "Solicita realizar una tarea. Ejemplo: 'Redacta una carta formal'.",
    "Comando": "Da una orden clara. Ejemplo: 'Genera un cÃ³digo Python para...'",

    "Zero-shot": "El modelo responde sin ejemplos previos. Ej: 'Â¿QuÃ© es la fotosÃ­ntesis?'",
    "Few-shot": "Se entregan algunos ejemplos para guiar la respuesta.",
    "CoT (Chain-of-Thought)": "Se pide razonamiento paso a paso para llegar a la respuesta.",
    "Chaining": "Se divide una tarea en pasos encadenados. El output de uno es el input del siguiente.",

    "Credenciales": "Evita pedir claves o datos sensibles. Usa prompts que promuevan buenas prÃ¡cticas.",
    "Privacidad": "Protege informaciÃ³n personal. No uses datos reales en tus prompts.",
    "Tareas": "Promueve aprendizaje. Evita respuestas sin explicaciÃ³n o con atajos.",
}

ejemplos = {
    "Pregunta directa": ["Â¿QuÃ© es la inteligencia artificial?"],
    "InstrucciÃ³n": ["Escribe una historia corta sobre un viaje al espacio."],
    "Comando": ["Genera un cÃ³digo Python para calcular el promedio de una lista."],

    "Zero-shot": ["Â¿QuÃ© es la fotosÃ­ntesis?"],
    "Few-shot": ["Traduce las siguientes frases al francÃ©s:\n- Hello â†’ Bonjour\n- Thank you â†’ Merci\n- Good morning â†’ ?"],
    "CoT (Chain-of-Thought)": [
        "Si un tren viaja a 80 km/h y recorre 240 km, Â¿cuÃ¡nto tiempo tarda? Explica tu razonamiento."
    ],
    "Chaining": [
        "Paso 1: Resume en 3 frases la RevoluciÃ³n Industrial.\nPaso 2: Expande cada frase en un pÃ¡rrafo detallado."
    ],

    "Credenciales": ["Â¿CÃ³mo guardar credenciales en un archivo `.env` y cargarlas de forma segura en Python?"],
    "Privacidad": ["ExplÃ­came cÃ³mo anonimizar datos sensibles correctamente."],
    "Tareas": ["Resuelve paso a paso la ecuaciÃ³n xÂ² + 5x + 6 = 0 usando factorizaciÃ³n."]
}

# Sidebar: selecciÃ³n de categorÃ­a y tipo
st.sidebar.title("ğŸ“š Tipos de Prompt")
categoria = st.sidebar.radio("Selecciona una categorÃ­a", list(categorias.keys()))
tipo = st.sidebar.radio("Selecciona un tipo", categorias[categoria])

# Mostrar explicaciÃ³n
st.subheader(f"ğŸ§© Tipo: {tipo}")
st.markdown(f"ğŸ” **DescripciÃ³n:** {explicaciones.get(tipo, 'DescripciÃ³n no disponible')}")

# Botones con ejemplos sugeridos
st.subheader("ğŸ’¡ Ejemplos sugeridos")
for i, ejemplo in enumerate(ejemplos[tipo]):
    if st.button(f"Usar ejemplo #{i+1}"):
        st.session_state.user_prompt = ejemplo

# Caja de texto editable
st.subheader("âœï¸ Escribe o edita tu prompt")
user_input = st.text_area("Prompt", st.session_state.get("user_prompt", ""), height=150)

# Chat real con OpenAI
if st.session_state.api_key.startswith("sk-"):

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "system", "content": "Eres un asistente educativo experto en prompts."}]

    if st.button("ğŸ’¬ Enviar al asistente"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.spinner("Pensando..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=st.session_state.messages
                )
                reply = response.choices[0].message.content
                st.session_state.messages.append({"role": "assistant", "content": reply})
                st.success("âœ… Respuesta generada")
                st.markdown(f"**ğŸ¤– Respuesta:**\n\n{reply}")
            except Exception as e:
                st.error(f"âŒ Error: {e}")

    with st.expander("ğŸ•‘ Historial"):
        for m in st.session_state.messages[1:]:
            st.markdown(f"**{m['role'].capitalize()}**: {m['content']}")
else:
    st.warning("Ingresa tu OpenAI API Key para utilizar el asistente.")
