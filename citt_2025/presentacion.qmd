---
title: "Taller de Python + IA para todos "
subtitle: "¬°Haz tu propio ChatGPT!"
author: 
- Sebasti√°n Flores
- Francisco Alfaro
- Valeska Canales
date: 02 Apr 2025
format:
  revealjs:
    width: 1245
    height: 700
    menu: false
    controls: true
    transition: fade
    auto-stretch: false
    embed-resources: false
    toc: false
    center: true
    slide-number: false
    preview-links: false
    title-slide-attributes: 
      data-background-image: images/background.jpg
    theme:
        - simple
    logo: images/citt.png
---

## ¬øQu√© dicen los diarios de la IA?

![](images/alarmismo.png){.fragment fig-align="center"}

------------------------------------------------------------------------

## SI presten atenci√≥n al hombre tras la cortina

{{< video videos/tras_la_cortina.mp4 >}}

------------------------------------------------------------------------

::: {.callout-tip title="Idea"}
Toda tecnolog√≠a suficientemente avanzada parece magia.

[**Arthur C. Clarke**]{style="text-align: right;"}
:::

------------------------------------------------------------------------

##  {background-image="images/background_slides3.png" background-opacity="0.3"}

::: {style="display: flex; justify-content: center; align-items: center; height: 60vh; flex-direction: column; text-align: center;"}
[Parte 1]{style="font-size: 1em"}

[La ilusi√≥n de la continuidad]{style="font-size: 1.5em"}
:::

------------------------------------------------------------------------

## Desaf√≠o

¬øQu√© contiene la siguiente cadena de bits?

[00000000]{style="font-size: 80px; margin: 0px; color: white"} [00101010]{style="font-size: 80px; margin: 0px;"}

------------------------------------------------------------------------

[00000000]{style="font-size: 80px; margin: 0px; color: white"} [00101010]{style="font-size: 80px; margin: 0px;"}

[Podr√≠a ser el n√∫mero 42 escrito en binario...]{.fragment}

------------------------------------------------------------------------

[00000000]{style="font-size: 80px; margin: 0px; color: white"} [00101010]{style="font-size: 80px; margin: 0px;"}

[Podr√≠a ser el car√°cter `*` en la convenci√≥n ascii...]{.fragment}

------------------------------------------------------------------------

[00000000]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00101010]{style="font-size: 80px; margin: 0px;"} [00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}

[Podr√≠a ser parte de un n√∫mero decimal, 0.4523 o $\pi$...]{.fragment}

------------------------------------------------------------------------

[10000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00100001]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [01000111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00001000]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00101010]{style="font-size: 80px; margin: 0px;"} [01000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [11111111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [11001101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [01000111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"} [01110111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}

[Podr√≠a ser parte de un archivo multimedia (video, imagen, audio, etc.)...]{.fragment}

------------------------------------------------------------------------

::: columns
::: {.column .fragment width="60%"}
<br><br>

-   **TODO** en el computador son bits
-   `representaci√≥n` `=` `bits` `+` `contexto`
:::

::: {.column width="40%"}
![](images/context.png){fig-align="center"}
:::
:::

------------------------------------------------------------------------

Alta fidelidad no es continuidad.

![](code/derivada_5.png){fig-align="center"}

------------------------------------------------------------------------

Alta fidelidad no es continuidad.

![](code/derivada_7.png){fig-align="center"}

------------------------------------------------------------------------

Alta fidelidad no es continuidad.

![](code/derivada_9.png){fig-align="center"}

------------------------------------------------------------------------

Alta fidelidad no es continuidad.

![](code/derivada_11.png){fig-align="center"}

------------------------------------------------------------------------

Alta fidelidad no es continuidad.

![](code/derivada_21.png){fig-align="center"}

------------------------------------------------------------------------

Alta fidelidad no es continuidad. [Pero puede ser suficiente...]{.fragment fragment-index="1"}

![](code/derivada_31.png){fig-align="center"}

------------------------------------------------------------------------

No necesitamos la realidad, necesitamos una buena aproximaci√≥n. Suficiente para enga√±ar a los sentidos.

![](images/celuloide.jpg){.fragment width="50%" fig-align="center"}

[Una pel√≠cula de 24 FPS es suficiente para enga√±ar al ojo humano.]{.fragment}

------------------------------------------------------------------------

## ¬øQu√© aprendimos?

-   Ninguna representaci√≥n en el computador es perfecta.
-   Los LLMs tampoco lo son‚Ä¶ ¬°y no tienen que serlo!

------------------------------------------------------------------------

##  {background-image="images/background_slides3.png" background-opacity="0.3"}

::: {style="display: flex; justify-content: center; align-items: center; height: 60vh; flex-direction: column; text-align: center;"}
[Parte 2]{style="font-size: 1em"}

[El computador parlanch√≠n]{style="font-size: 1.5em"}
:::

------------------------------------------------------------------------

## ¬øC√≥mo representar una palabra?

![](images/representacion.png){.fragment fig-align="center"}

------------------------------------------------------------------------

## Representaci√≥n textual

Si solo queremos transcribir texto, basta con representar cada letra con una secuencia de bits, y almacenarla.

::: columns
::: {.column .fragment .center style="font-size: 24px;"}
ASCII

-   1 byte (8 bits): 128 car√°cteres posibles
-   0 (48) ... 9 (57)
-   A (65) ... Z (90)
-   a (97) ... z (122)
-   Problema: Faltan muchos car√°cteres: √ë, √±, √°, √©, √≠, √≥, √∫, u
:::

::: {.column .fragment .center style="font-size: 24px;"}
UTF-8

-   1 a 4 bytes (8 a 32 bits)
-   Mantiene ASCII sin cambios
-   Permite representar alfabetos latinos, griego, √°rabe, sir√≠aco, thaana, y n'ko, adem√°s de caracteres chinos, japoneses y coreanos.
-   Incluye emojis üòÅ, simbolos ‚úÖ y mil cosas m√°s üóø
:::
:::

------------------------------------------------------------------------

## Representaci√≥n sem√°ntica

::: columns
::: {.column .fragment width="60%"}
<br>

-   **Sem√°ntica** significa **el sentido o significado** de las palabras.
-   Necesitamos guardarla como un **todo** o dividirla en **partes con sentido** (tokens).
:::

::: {.column width="40%"}
![](images/semantica.jpg){fig-align="center"}
:::
:::

------------------------------------------------------------------------

## Actividad 2.1

-   Actividad: Ir a <https://platform.openai.com/tokenizer>
-   Objetivo: Evaluar distintos textos, en distintos idiomas.

::: panel-tabset
## Ejemplo 1

Espa√±ol: [*La inform√°tica,‚Äã tambi√©n llamada computaci√≥n, es el √°rea de la ciencia que se encarga de estudiar la administraci√≥n de m√©todos, t√©cnicas y procesos con el fin de almacenar, procesar y transmitir informaci√≥n y datos en formato digital.*]{style="font-size: 24px;"}

## Ejemplo 2

Ingl√©s: [*Computing is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes the study and experimentation of algorithmic processes, and the development of both hardware and software. Computing has scientific, engineering, mathematical, technological, and social aspects.*]{style="font-size: 24px;"}
:::

<br>

------------------------------------------------------------------------

::: {style="text-align: center;"}
<iframe
    src="https://agents-course-the-tokenizer-playground.static.hf.space"
    frameborder="0"
    width="950"
    height="650"
  ></iframe>
:::

------------------------------------------------------------------------

## üí° Aprendizajes

-   Palabra ‚â† Token
-   Cada **token** tiene un **ID √∫nico**\
-   En ingl√©s, **100 tokens ‚âà 75 palabras**\
-   Dos palabras **iguales** pueden tener **tokens distintos**, seg√∫n el contexto

<br>

------------------------------------------------------------------------

## LLM = Large Language Model

![](images/llm1.png){.fragment fig-align="center" width="40%"}

------------------------------------------------------------------------

## Diagrama t√©cnico de un LLM

::: r-stack
<br>

![](images/gif1.gif){.fragment .fade-in-then-out fig-align="center"}

![](images/gif2.gif){.fragment fig-align="center"}
:::

------------------------------------------------------------------------

## Actividad 2.2

-   Actividad: Ir a <https://huggingface.co/spaces/alonsosilva/NextTokenPrediction>
-   **Objetivo**: Observar la lista de token que se muestran como posible continuaci√≥n del texto.

<br><br>

------------------------------------------------------------------------

::: {style="text-align: center;"}
<iframe
    src="https://agents-course-decoding-visualizer.hf.space"
    frameborder="0"
    width="950"
    height="650"
  ></iframe>
:::

------------------------------------------------------------------------

## üí° Aprendizajes

-   El LLM **no reflexiona**, solo predice el **token m√°s probable**.\
-   La predicci√≥n es **secuencial**, token por token.\
-   No tiene **memoria**: siempre parte desde cero.

::: notes
Comparar con una multiplicaci√≥n de matrices. La matriz no recuerda que ya hizo multiplicaciones antes.
:::

------------------------------------------------------------------------

## El negocio de los LLMs

::: columns
::: {.column .fragment width="60%"}
<br>

-   Los LLMs tienen **billones de par√°metros**.\
-   Se entrenan con **textos masivos** (internet, libros, etc.).\
-   Requieren **mucho poder computacional** (GPUs por horas).
:::

::: {.column width="40%"}
![](images/gpu.png){fig-align="center"}
:::
:::

------------------------------------------------------------------------

## El negocio de los LLMs

No existe solo chatGPT (OpenAI): todos quieren un pedazo de la torta:

::: columns
::: {.column .fragment .center width="50%"}
**Los de pago:**

-   GPT-4 (OpenAI)
-   Gemini (Google)
-   Claude (Anthropic)
-   ...
:::

::: {.column .fragment .center width="50%"}
**Los de c√≥digo abierto:**

-   Llama (Meta)
-   Qwen (Baidu)
-   DeepSeek (China)
-   ...
:::
:::

------------------------------------------------------------------------

##  {background-image="images/background_slides3.png" background-opacity="0.3"}

::: {style="display: flex; justify-content: center; align-items: center; height: 60vh; flex-direction: column; text-align: center;"}
[Parte 3]{style="font-size: 1em"}

[¬°Hazlo tu mismo!]{style="font-size: 1.5em"}
:::

------------------------------------------------------------------------

## Actividad 1

::: panel-tabset
## üß† Teor√≠a

**¬øC√≥mo podemos emular chatGPT?**

::: columns
::: {.column .center width="50%"}
*Ejecutar localmente LLM:*

-   Configuraci√≥n compleja
-   Hardware costoso
:::

::: {.column .fragment width="50%"}
*Consumir una API de LLM*

-   Simple y pago por uso
-   Varias opciones y proveedores
:::
:::

<br>

## üõ†Ô∏è Actividad

-   Actividad: Ir a <https://cittripio.streamlit.app/v1>
-   Objetivo: Lograr que el bot responda "una pregunta"
    -   Tiempo: 5 minutos

## Code

<iframe src="https://cittripio.streamlit.app/v1?embed=true" style="height: 450px; width: 100%;">

</iframe>

## üí° Aprendizajes

-   El LLM responde en funci√≥n del prompt.
-   El prompt puede pedir cualquier cosa.
-   Prompts cortos entregan resultados muy variables.
:::

------------------------------------------------------------------------

## Actividad 2

::: panel-tabset
## üß† Teor√≠a

-   Los LLMs no tienen personalidad propia, pero t√∫ puedes definir c√≥mo deben comportarse mediante el prompt.
-   Esto se logra describiendo expl√≠citamente el rol, el tono y el estilo que deseas que adopte el modelo.

<br>

## üõ†Ô∏è Actividad

-   Actividad: Ir a <https://cittripio.streamlit.app/vdos>
-   **Objetivo**:
    -   [O1: Hacer 2 preguntas relacionadas.]{style="font-size: 24px;"}
    -   [O2: Cambiar la personalidad del bot.]{style="font-size: 24px;"}
    -   Tiempo: 5 minutos

## üí° Aprendizajes

-   Separar en contexto y pregunta permite imponer una ‚Äúpersonalidad‚Äù o ciertas caracter√≠sticas.
-   Un LLM no tiene memoria.
:::

------------------------------------------------------------------------

## Actividad 3

::: panel-tabset
## üß† Teor√≠a I

**¬øPor qu√© chatGPT si tiene memoria?**

*Muy simple*: Pasemosle la historia de la conversaci√≥n en cada prompt.

-   Opci√≥n 1: Pasarle todo el texto.
-   Opci√≥n 2: Pasarle un resumen de la conversaci√≥n.

<br>

## üß† Teor√≠a II

**¬øQu√© es la temperatura?**

Es un par√°metro que controla que tan aleatoria es la elecci√≥n del siguiente token. - Temperatura = 0: Muy determinista. - Temperatura = 1: Muy aleatorio.

## üõ†Ô∏è Actividad

-   Actividad: Ir a <https://cittripio.streamlit.app/vf>
-   **Objetivo**:
    -   [O1: Lograr que cittripio le responda a Luke Skywalker que es su padre.]{style="font-size: 24px;"}
    -   [O2: Cambiar la personalidad de cittripio por cualquier otro personaje (no necesariamente de Star Wars).]{style="font-size: 24px;"}
    -   Tiempo: 5 minutos

## üí° Aprendizajes

-   El LLM necesita tener como input todo el contexto e historia en el prompt.
-   Las APIs agregan muchas opciones para simplificar y manejar todo esto convenientemente.
:::

------------------------------------------------------------------------

##  {background-image="images/background_slides3.png" background-opacity="0.3"}

::: {style="display: flex; justify-content: center; align-items: center; height: 60vh; flex-direction: column; text-align: center;"}
[Parte 4]{style="font-size: 1em"}

[Conclusi√≥n]{style="font-size: 1.5em"}
:::

------------------------------------------------------------------------

## üöÄ Conclusi√≥n

‚úÖ LLMs no son magia: es tecnolog√≠a.

‚úÖ Cualquiera puede comenzar a crear soluciones con LLMs.

‚úÖ Conocer como funcionan LLMs permite usarlos mejor.

‚úÖ Existen muchos recursos gratuitos para aprender y jugar.

<br><br>

------------------------------------------------------------------------

## üéâ ¬°Gracias por Participar! {background-image="images/background.jpg" background-opacity="0.25"}

::: columns
::: {.column width="50%"}
<br>

‚ùì¬øPreguntas?

üëè Responder [encuesta](https://docs.google.com/forms/d/e/1FAIpQLSd2CseqhHUjdmvr46ZDb_Aa2iUYEjLAIE4MwLztled5ytRJvg/viewform?usp=dialog)

ü•≥ Difrutar del Evento!
:::

::: {.column width="50%" align="center"}
![](images/qr_citt2.png){width="400"}
:::
:::

> üîó Nuestro Sitio Web: [seth-nut.github.io/resources](https://seth-nut.github.io/resources/)

```{=html}
<style>


.reveal .slide-logo {
   max-height: 2em !important;
}



</style>
```